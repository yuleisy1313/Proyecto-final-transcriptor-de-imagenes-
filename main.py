import gradio as gr
import easyocr
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from deep_translator import GoogleTranslator
from PIL import Image

# Inicializar el lector OCR
reader = easyocr.Reader(['es', 'en'])

# Cargar el modelo y el tokenizador para an√°lisis de emociones
tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-emotion")
model = AutoModelForSeq2SeqLM.from_pretrained("mrm8488/t5-base-finetuned-emotion")

# Funci√≥n para detectar emoci√≥n
def detectar_emocion(texto):
    if not texto.strip():
        return "‚ùå No se detect√≥ texto para analizar."

    # Traducir al ingl√©s
    texto_en = GoogleTranslator(source='auto', target='en').translate(texto)
    
    # Generar emoci√≥n
    entrada = tokenizer.encode(f"emotion: {texto_en}", return_tensors="pt")
    salida = model.generate(entrada, max_length=20)
    emocion_en = tokenizer.decode(salida[0], skip_special_tokens=True)

    # Traducir la emoci√≥n al espa√±ol si es necesario
    emocion_esp = GoogleTranslator(source='en', target='es').translate(emocion_en).capitalize()

    return f"üß† Este texto transmite una sensaci√≥n de: **{emocion_esp}**"

# Funci√≥n principal
def analizar_imagen(imagen):
    # OCR con EasyOCR
    resultado = reader.readtext(imagen, detail=0)
    texto_extraido = " ".join(resultado)

    if not texto_extraido.strip():
        return "‚ùå No se encontr√≥ texto en la imagen.", ""

    emocion = detectar_emocion(texto_extraido)
    return texto_extraido, emocion

# Interfaz de Gradio
gr.Interface(
    fn=analizar_imagen,
    inputs=gr.Image(type="filepath", label="Sube una imagen con texto"),
    outputs=[
        gr.Textbox(label="üìù Texto extra√≠do"),
        gr.Textbox(label="üí¨ An√°lisis emocional")
    ],
    title="üñºÔ∏è Transcriptor de Imagenes",
    description="Este sistema detecta el texto de una imagen y te dice qu√© emoci√≥n transmite (como alegr√≠a, tristeza, amor, etc.)."
).launch()
